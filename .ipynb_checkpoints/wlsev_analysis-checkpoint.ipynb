{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WLS-EV Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KIT CRAM Seminar WS17/18\n",
    "Algorithmic Design - Least squares estimates weighted by ex-ante return variance (WLS-EV)\n",
    "\"\"\"\n",
    "\n",
    "__author__ = 'Tobias Kuhlmann'\n",
    "\n",
    "# Import own libraries\n",
    "from variance_estimation import ExAnteVariance\n",
    "from wlsev_model import Wlsev_model\n",
    "from ols_model import OLS_model\n",
    "import visualisation\n",
    "from simon_ols_model import OLS\n",
    "# import general packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in log return data and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import price data and calc log returns\n",
    "# --------------------------------------------------\n",
    "es_50_prices = pd.read_csv('data/eurostoxx50_prices_eod.csv', parse_dates=True)\n",
    "# set index, rename and check\n",
    "es_50_prices['loctimestamp'] =pd.to_datetime(es_50_prices['loctimestamp'])\n",
    "es_50_prices = es_50_prices.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_prices = es_50_prices.set_index('date')\n",
    "\n",
    "#Log Returns\n",
    "es_50_logret = es_50_prices\n",
    "es_50_logret['logreturns'] = (np.log(es_50_prices['lastprice'] / es_50_prices['lastprice'].shift(1))).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import vol data\n",
    "# --------------------------------------------------\n",
    "es_50_vol = pd.read_csv('data/es50_volatility.csv', parse_dates=True)\n",
    "# Transform dates\n",
    "es_50_vol['loctimestamp'] = pd.to_datetime(es_50_vol['loctimestamp'])\n",
    "# Delete unnecessary columns\n",
    "del es_50_vol['instrumentid']\n",
    "# Calculate variance from vol\n",
    "es_50_vol['volatility'] = es_50_vol['volatility'] ** 2\n",
    "# set index, rename and check\n",
    "es_50_vol = es_50_vol.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_vol = es_50_vol.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implied volatility data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import implied volatility\n",
    "# --------------------------------------------------\n",
    "es_50_imp_vol = pd.read_csv('data/es50_implied_volatility.csv', parse_dates=True)\n",
    "# Transform dates\n",
    "es_50_imp_vol['loctimestamp'] = pd.to_datetime(es_50_imp_vol['loctimestamp'])\n",
    "# Delete unnecessary columns\n",
    "del es_50_imp_vol['instrumentid']\n",
    "del es_50_imp_vol['maturity']\n",
    "# Calculate implied variance from implied vol\n",
    "es_50_imp_vol['implied_vol'] = es_50_imp_vol['measure'] ** 2\n",
    "# set index, rename and check\n",
    "es_50_imp_vol = es_50_imp_vol.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_imp_vol = es_50_imp_vol.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riskfree rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import riskfree rate data\n",
    "# --------------------------------------------------\n",
    "rf = pd.read_csv('data/riskfree_rate.csv', parse_dates=True, sep=';')\n",
    "# Transform dates\n",
    "rf['loctimestamp'] = pd.to_datetime(rf['loctimestamp'])\n",
    "# set index, rename and check\n",
    "rf = rf.rename(columns={'loctimestamp': 'date'})\n",
    "rf = rf.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VRP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VRP data\n",
    "# --------------------------------------------------\n",
    "es_50_vrp = pd.read_csv('data/es50_vrp.csv', parse_dates=True)\n",
    "# Transform dates\n",
    "es_50_vrp['loctimestamp'] = pd.to_datetime(es_50_vrp['loctimestamp'])\n",
    "# set index, rename and check\n",
    "es_50_vrp = es_50_vrp.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_vrp = es_50_vrp.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ERP from logrets and riskfree rate\n",
    "# Take risk free rate maturity 7 (smallest maturity)\n",
    "rf_mat7 = rf[rf['daystomaturity'] == 7]\n",
    "# Calculate ERP = logrets - rf\n",
    "es_50_erp = (es_50_logret['logreturns'] - rf_mat7['riskfree']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Moments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Q-Moments data\n",
    "# --------------------------------------------------\n",
    "es_50_q = pd.read_csv('data/FiglewskiStandardizationEOD_DE0009652396D1_Qmoments.csv', parse_dates=True, sep = ';')\n",
    "es_50_q.head(5)\n",
    "# Transform dates\n",
    "es_50_q['loctimestamp'] = pd.to_datetime(es_50_q['loctimestamp'])\n",
    "# set index, rename and check\n",
    "es_50_q = es_50_q.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_q = es_50_q.set_index('date')\n",
    "\n",
    "# Delete unnecessary columns\n",
    "del es_50_q['underlyingprice']\n",
    "del es_50_q['underlyingforwardprice']\n",
    "del es_50_q['Q_cubic']\n",
    "del es_50_q['Q_quartic']\n",
    "\n",
    "# Split maturities into seperate columns\n",
    "es_50_q_7 = es_50_q[es_50_q['daystomaturity'] == 7]\n",
    "es_50_q_30 = es_50_q[es_50_q['daystomaturity'] == 30]\n",
    "es_50_q_60 = es_50_q[es_50_q['daystomaturity'] == 60]\n",
    "es_50_q_91 = es_50_q[es_50_q['daystomaturity'] == 91]\n",
    "es_50_q_182 = es_50_q[es_50_q['daystomaturity'] == 182]\n",
    "es_50_q_365 = es_50_q[es_50_q['daystomaturity'] == 365]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-Moments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/tobias/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/tobias/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 var  skewness   kurtosis\n",
      "2000-06-29  0.000122 -2.222407  10.319956\n",
      "2000-06-30  0.000104  1.915765  13.727356\n",
      "2000-07-03  0.000060  0.928470   4.888393\n",
      "2000-07-04  0.000044 -1.222261   9.323549\n",
      "2000-07-05  0.000084 -0.563166   4.413222\n",
      "2000-07-06  0.000072 -0.468666   3.909777\n",
      "2000-07-07  0.000100  2.911292  16.360345\n",
      "2000-07-10  0.000064  2.003450  13.168587\n",
      "2000-07-11  0.000074 -0.490250   8.511618\n",
      "2000-07-12  0.000045  0.195632   4.471447\n",
      "2000-07-13  0.000043  0.221820   3.217365\n",
      "2000-07-14  0.000039  0.822575   6.843976\n",
      "2000-07-17  0.000036  1.042012   5.981724\n",
      "2000-07-18  0.000051 -1.035490   4.282081\n",
      "2000-07-19  0.000032 -0.168422   3.408400\n",
      "2000-07-20  0.000053 -0.288610   8.190756\n",
      "2000-07-21  0.000062 -0.994505   6.672594\n",
      "2000-07-24  0.000061  0.910416   4.149966\n",
      "2000-07-25  0.000038 -0.422312   3.060479\n",
      "2000-07-26  0.000060  2.138868  15.002089\n",
      "2000-07-27  0.000915 -3.798243  34.170810\n",
      "2000-07-28  0.000106 -0.827571   5.650318\n",
      "2000-07-31  0.000086  0.911229   7.319840\n",
      "2000-08-01  0.000048 -1.726165   8.715672\n",
      "2000-08-02  0.000060  0.479425   4.542269\n",
      "2000-08-03  0.000097 -1.290510   6.839468\n",
      "2000-08-04  0.000108  2.617975  17.190244\n",
      "2000-08-07  0.000057  1.047249   8.116303\n",
      "2000-08-08  0.000054  0.609227   5.254934\n",
      "2000-08-09  0.000067  1.990698  14.309833\n",
      "...              ...       ...        ...\n",
      "2005-06-21  0.000027  2.526698  17.047103\n",
      "2005-06-22  0.000021  0.244902   5.301750\n",
      "2005-06-23  0.000021  0.504366   5.926332\n",
      "2005-06-24  0.000076 -7.068935  64.453048\n",
      "2005-06-27  0.000071 -6.900213  62.448100\n",
      "2005-06-28  0.000016  2.451888  10.518992\n",
      "2005-06-29  0.000027  1.954171  13.330644\n",
      "2005-06-30  0.000020  0.966410   6.667348\n",
      "2005-07-01  0.000031  1.671652   9.606821\n",
      "2005-07-04  0.000011  0.909692   8.420505\n",
      "2005-07-05  0.000022 -0.278142   4.344953\n",
      "2005-07-06  0.000031  2.637229  15.021479\n",
      "2005-07-07  0.000540 -2.302449  14.199267\n",
      "2005-07-08  0.000121  6.274982  54.563374\n",
      "2005-07-11  0.000036  4.367975  32.610436\n",
      "2005-07-12  0.000033 -0.633154   6.359124\n",
      "2005-07-13  0.000023  0.906260   5.971539\n",
      "2005-07-14  0.000031  1.890442  12.541098\n",
      "2005-07-15  0.000026  0.730682   8.406896\n",
      "2005-07-18  0.000015 -0.036039   3.188961\n",
      "2005-07-19  0.000031  2.508290  11.642538\n",
      "2005-07-20  0.000036 -0.412546   5.673020\n",
      "2005-07-21  0.000231  0.928197  10.253960\n",
      "2005-07-22  0.000033 -1.694825  10.931625\n",
      "2005-07-25  0.000027  1.237398  10.161284\n",
      "2005-07-26  0.000020 -0.185742   3.915650\n",
      "2005-07-27  0.000022  0.008301   9.061873\n",
      "2005-07-28  0.000039  4.608036  35.736732\n",
      "2005-07-29  0.000034  0.946566   8.119250\n",
      "2005-08-01  0.000009  2.609799  22.264759\n",
      "\n",
      "[1294 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import 5 min price data and calc log returns\n",
    "# --------------------------------------------------\n",
    "es_50_prices_5 = pd.read_csv('data/eurostoxx50_prices_5m.csv', parse_dates=True, sep=';')\n",
    "# set index, rename and check\n",
    "es_50_prices_5 = es_50_prices_5.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_prices_5['date'] = pd.to_datetime(es_50_prices_5['date'], errors='coerce')\n",
    "es_50_prices_5 = es_50_prices_5.set_index('date')\n",
    "\n",
    "#Log Returns\n",
    "es_50_logret_5 = es_50_prices_5\n",
    "es_50_logret_5['logreturns'] = np.log(es_50_prices_5['price'] / es_50_prices_5['price'].shift(1))\n",
    "es_50_logret_5 = es_50_logret_5.dropna()\n",
    "\n",
    "# Count of values per day\n",
    "N = (es_50_logret_5.loc[(es_50_logret_5.index >= '2004-07-04 00:00:00') & (es_50_logret_5.index <= '2004-07-06 00:00:00')]).shape[0]\n",
    "\n",
    "# Calculate moments after Amaya, Christoffersen, Jacobs, Vasquez (2015) - Does realized skewness predict equity returns\n",
    "es_50_logret_5['logreturns_pow2'] = es_50_logret_5['logreturns'] ** 2\n",
    "es_50_logret_5['logreturns_pow3'] = es_50_logret_5['logreturns'] ** 3\n",
    "es_50_logret_5['logreturns_pow4'] = es_50_logret_5['logreturns'] ** 4\n",
    "\n",
    "\n",
    "# Var = sum of intraday squared returns\n",
    "es_50_P_1 = es_50_logret_5.groupby(es_50_logret_5.index.date).sum()\n",
    "es_50_P_1 = es_50_P_1.rename(columns={'logreturns_pow2': 'var'})\n",
    "\n",
    "# Skewness 1 day\n",
    "es_50_P_1['skewness'] = ( np.sqrt(N) * es_50_P_1['logreturns_pow3']) / (es_50_P_1['var'] ** (3 / 2) )\n",
    "\n",
    "# Kurtosis1 day\n",
    "es_50_P_1['kurtosis'] = N * es_50_P_1['logreturns_pow4'] / (es_50_P_1['var'] ** 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "del es_50_P_1['price']\n",
    "del es_50_P_1['logreturns']\n",
    "del es_50_P_1['logreturns_pow3']\n",
    "del es_50_P_1['logreturns_pow4']\n",
    "\n",
    "print(es_50_P_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fama-French data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Fama French Factors\n",
    "# --------------------------------------------------\n",
    "# HML and SMB\n",
    "es_50_ff = pd.read_csv('data/FamaFrench_Europe_3_Factors_Daily.csv', parse_dates=True, skiprows=6)\n",
    "es_50_ff = es_50_ff.rename(columns={'Unnamed: 0': 'date'})\n",
    "es_50_ff['date'] = pd.to_datetime(es_50_ff['date'], format = '%Y%m%d')\n",
    "es_50_ff = es_50_ff.set_index('date')\n",
    "\n",
    "# Momentum Factor\n",
    "es_50_ff2 = pd.read_csv('data/FamaFrench_Europe_MOM_Factor_Daily.csv', parse_dates=True, skiprows=6)\n",
    "es_50_ff2 = es_50_ff2.rename(columns={'Unnamed: 0': 'date'})\n",
    "es_50_ff2['date'] = pd.to_datetime(es_50_ff2['date'], format = '%Y%m%d')\n",
    "es_50_ff2 = es_50_ff2.set_index('date')\n",
    "\n",
    "# Join and drop na's\n",
    "es_50_ff = es_50_ff.join(es_50_ff2).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join data for correct dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join vol and implied vol\n",
    "print(es_50_logret['logreturns'].shape)\n",
    "print(es_50_vol.shape)\n",
    "print(es_50_imp_vol.shape)\n",
    "print(es_50_vrp.shape)\n",
    "print(es_50_erp.shape)\n",
    "print(es_50_q.shape)\n",
    "print(es_50_P.shape)\n",
    "print(es_50_ff.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Ex ante Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model and Analysis\n",
    "# ==================================================\n",
    "#\n",
    "# 1. Estimate (sigma_t)2, the (ex ante) conditional variance of next-period unexpected returns epsilon_(t+1)\n",
    "# using a HAR-RV (Hierachical Autoregressive-Realized Variance) Model from Corsi (2009)\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# First, instantiate object\n",
    "# no implied vol\n",
    "ea_var_obj = ExAnteVariance(es_50_vol)\n",
    "# implied vol exists\n",
    "# ea_var_obj = ExAnteVariance(es_50_imp_vol, es_50_imp_vol['implied_vol'])\n",
    "\n",
    "# Estimate Variance\n",
    "result = ea_var_obj.estimate_variance()\n",
    "result = result.dropna()\n",
    "\n",
    "# Join returns and estimated variance\n",
    "wlsev_var_rets = es_50_logret.join(result).dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WLS-EV and benchmark estimations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress returns on returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forecast horizon 1, 5 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. least squares estimates weighted by ex-ante return variance (WLS-EV) using Johnson (2016)\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for i in (1,5,10):\n",
    "    # set forecast_horizon\n",
    "    forecast_horizon = i\n",
    "\n",
    "    # WLS-EV\n",
    "    wlsev_obj = Wlsev_model(wlsev_var_rets['logreturns'][:-1].as_matrix(), wlsev_var_rets['logreturns'][1:].as_matrix(), wlsev_var_rets['vol_daily_est'][:-1].as_matrix(), forecast_horizon)\n",
    "    wlsev_obj.fit()\n",
    "    # OOS evaluation to get Rsquared\n",
    "    wlsev_obj.evaluate()\n",
    "    wlsev_obj.print_results()\n",
    "    wlsev_obj.plot_results()\n",
    "    # get data\n",
    "    X, Y, y_wlsev = wlsev_obj.get_plot_data_wlsev()\n",
    "\n",
    "    # OLS\n",
    "    ols_obj = OLS_model(wlsev_var_rets['logreturns'][:-1].as_matrix(), wlsev_var_rets['logreturns'][1:].as_matrix(), forecast_horizon)\n",
    "    ols_obj.fit()\n",
    "    # OOS evaluation to get Rsquared\n",
    "    ols_obj.evaluate()\n",
    "    ols_obj.print_results()\n",
    "    ols_obj.plot_results()\n",
    "    # get data\n",
    "    X, Y, y_ols = ols_obj.get_plot_data_ols()\n",
    "\n",
    "\n",
    "    # Visualisation\n",
    "    # ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # time series plot\n",
    "    visualisation.plot_results(X,Y,y_wlsev, y_ols)\n",
    "    # scatter plot\n",
    "    visualisation.plot_scatter(X,Y,y_wlsev, y_ols)\n",
    "\n",
    "\n",
    "    # Get Simon's OLS estimation results\n",
    "    if forecast_horizon == 1:\n",
    "        ols_model = OLS(wlsev_var_rets['logreturns'][:-1].as_matrix(), wlsev_var_rets['logreturns'][1:].as_matrix())\n",
    "        ols_model.fit()\n",
    "        ols_model.printResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress returns on VRP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join vrp data with wls-ev log rets and ex ante variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_50_vrp_rets_var = wlsev_var_rets.join(es_50_vrp).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### forecast horizon months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set forecast_horizon\n",
    "for i in (1,22,44, 66, 88):\n",
    "    forecast_horizon = i\n",
    "\n",
    "    # WLS-EV\n",
    "    wlsev_obj = Wlsev_model(es_50_vrp_rets_var['vrp'][:-1].as_matrix(), es_50_vrp_rets_var['logreturns'][1:].as_matrix(), es_50_vrp_rets_var['vol_daily_est'][:-1].as_matrix(), forecast_horizon)\n",
    "    wlsev_obj.fit()\n",
    "    # OOS evaluation to get Rsquared\n",
    "    wlsev_obj.evaluate()\n",
    "    wlsev_obj.print_results()\n",
    "    wlsev_obj.plot_results()\n",
    "    # get data\n",
    "    X, Y, y_wlsev = wlsev_obj.get_plot_data_wlsev()\n",
    "\n",
    "    # OLS\n",
    "    ols_obj = OLS_model(es_50_vrp_rets_var['vrp'][:-1].as_matrix(), es_50_vrp_rets_var['logreturns'][1:].as_matrix(), forecast_horizon)\n",
    "    ols_obj.fit()\n",
    "    # OOS evaluation to get Rsquared\n",
    "    ols_obj.evaluate()\n",
    "    ols_obj.print_results()\n",
    "    # get data\n",
    "    X, Y, y_ols = ols_obj.get_plot_data_ols()\n",
    "\n",
    "\n",
    "    # Visualisation\n",
    "    # ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # time series plot\n",
    "    visualisation.plot_results(X,Y,y_wlsev, y_ols)\n",
    "    # scatter plot\n",
    "    visualisation.plot_scatter(X,Y,y_wlsev, y_ols)\n",
    "\n",
    "    # Get Simon's OLS estimation results\n",
    "    if forecast_horizon == 1:\n",
    "        ols_model = OLS(es_50_vrp_rets_var['vrp'][:-1].as_matrix(), es_50_vrp_rets_var['logreturns'][1:].as_matrix())\n",
    "        ols_model.fit()\n",
    "        ols_model.printResults()\n",
    "        ols_obj.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress ERP on VRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress P-Moments on Q-Moments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress Fama French Factors on Q-Moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
