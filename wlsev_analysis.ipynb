{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WLS-EV Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KIT CRAM Seminar WS17/18\n",
    "Algorithmic Design - Least squares estimates weighted by ex-ante return variance (WLS-EV)\n",
    "\"\"\"\n",
    "\n",
    "__author__ = 'Tobias Kuhlmann'\n",
    "\n",
    "# Import own libraries\n",
    "from variance_estimation import ExAnteVariance\n",
    "from wlsev_model import Wlsev_model\n",
    "from ols_model import OLS_model\n",
    "import visualisation\n",
    "from simon_ols_model import OLS\n",
    "# import general packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in log return data and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import price data and calc log returns\n",
    "# --------------------------------------------------\n",
    "es_50_prices = pd.read_csv('data/eurostoxx50_prices_eod.csv', parse_dates=True)\n",
    "# set index, rename and check\n",
    "es_50_prices['loctimestamp'] =pd.to_datetime(es_50_prices['loctimestamp'])\n",
    "es_50_prices = es_50_prices.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_prices = es_50_prices.set_index('date')\n",
    "\n",
    "#Log Returns\n",
    "es_50_logret = es_50_prices\n",
    "es_50_logret['logreturns'] = (np.log(es_50_prices['lastprice'] / es_50_prices['lastprice'].shift(1))).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import vol data\n",
    "# --------------------------------------------------\n",
    "es_50_vol = pd.read_csv('data/es50_volatility.csv', parse_dates=True)\n",
    "# Transform dates\n",
    "es_50_vol['loctimestamp'] = pd.to_datetime(es_50_vol['loctimestamp'])\n",
    "# Delete unnecessary columns\n",
    "del es_50_vol['instrumentid']\n",
    "# Calculate variance from vol\n",
    "es_50_vol['volatility'] = es_50_vol['volatility'] ** 2\n",
    "# set index, rename and check\n",
    "es_50_vol = es_50_vol.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_vol = es_50_vol.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implied volatility data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import implied volatility\n",
    "# --------------------------------------------------\n",
    "es_50_imp_vol = pd.read_csv('data/es50_implied_volatility.csv', parse_dates=True)\n",
    "# Transform dates\n",
    "es_50_imp_vol['loctimestamp'] = pd.to_datetime(es_50_imp_vol['loctimestamp'])\n",
    "# Delete unnecessary columns\n",
    "del es_50_imp_vol['instrumentid']\n",
    "del es_50_imp_vol['maturity']\n",
    "# Calculate implied variance from implied vol\n",
    "es_50_imp_vol['implied_vol'] = es_50_imp_vol['measure'] ** 2\n",
    "# set index, rename and check\n",
    "es_50_imp_vol = es_50_imp_vol.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_imp_vol = es_50_imp_vol.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riskfree rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import riskfree rate data\n",
    "# --------------------------------------------------\n",
    "rf = pd.read_csv('data/riskfree_rate.csv', parse_dates=True, sep=';')\n",
    "# Transform dates\n",
    "rf['loctimestamp'] = pd.to_datetime(rf['loctimestamp'])\n",
    "# set index, rename and check\n",
    "rf = rf.rename(columns={'loctimestamp': 'date'})\n",
    "rf = rf.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VRP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VRP data\n",
    "# --------------------------------------------------\n",
    "es_50_vrp = pd.read_csv('data/es50_vrp.csv', parse_dates=True)\n",
    "# Transform dates\n",
    "es_50_vrp['loctimestamp'] = pd.to_datetime(es_50_vrp['loctimestamp'])\n",
    "# set index, rename and check\n",
    "es_50_vrp = es_50_vrp.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_vrp = es_50_vrp.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ERP from logrets and riskfree rate\n",
    "# Take risk free rate maturity 7 (smallest maturity)\n",
    "rf_mat7 = rf[rf['daystomaturity'] == 7]\n",
    "# Calculate ERP = logrets - rf\n",
    "es_50_erp = (es_50_logret['logreturns'] - rf_mat7['riskfree']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Moments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Q-Moments data\n",
    "# --------------------------------------------------\n",
    "es_50_q = pd.read_csv('data/FiglewskiStandardizationEOD_DE0009652396D1_Qmoments.csv', parse_dates=True, sep = ';')\n",
    "es_50_q.head(5)\n",
    "# Transform dates\n",
    "es_50_q['loctimestamp'] = pd.to_datetime(es_50_q['loctimestamp'])\n",
    "# set index, rename and check\n",
    "es_50_q = es_50_q.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_q = es_50_q.set_index('date')\n",
    "\n",
    "# Delete unnecessary columns\n",
    "del es_50_q['underlyingprice']\n",
    "del es_50_q['underlyingforwardprice']\n",
    "del es_50_q['Q_cubic']\n",
    "del es_50_q['Q_quartic']\n",
    "\n",
    "# Split maturities into seperate columns\n",
    "es_50_q_7 = es_50_q[es_50_q['daystomaturity'] == 7]\n",
    "es_50_q_30 = es_50_q[es_50_q['daystomaturity'] == 30]\n",
    "es_50_q_60 = es_50_q[es_50_q['daystomaturity'] == 60]\n",
    "es_50_q_91 = es_50_q[es_50_q['daystomaturity'] == 91]\n",
    "es_50_q_182 = es_50_q[es_50_q['daystomaturity'] == 182]\n",
    "es_50_q_365 = es_50_q[es_50_q['daystomaturity'] == 365]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-Moments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/tobias/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/tobias/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 price  logreturns       var  logreturns_pow3  \\\n",
      "2000-06-29         NaN         NaN       NaN              NaN   \n",
      "2000-06-30         NaN         NaN       NaN              NaN   \n",
      "2000-07-03         NaN         NaN       NaN              NaN   \n",
      "2000-07-04         NaN         NaN       NaN              NaN   \n",
      "2000-07-05         NaN         NaN       NaN              NaN   \n",
      "2000-07-06         NaN         NaN       NaN              NaN   \n",
      "2000-07-07  4877149.04    0.003963  0.000586     1.238573e-07   \n",
      "2000-07-10  4902381.04    0.039197  0.000528     5.048774e-07   \n",
      "2000-07-11  4913945.92    0.016572  0.000498     2.818514e-07   \n",
      "2000-07-12  4926161.61    0.011909  0.000482     2.459086e-07   \n",
      "2000-07-13  4937350.13    0.021682  0.000482     2.857081e-07   \n",
      "2000-07-14  4953743.46    0.029337  0.000436     3.456632e-07   \n",
      "2000-07-17  4980942.13    0.038981  0.000400     3.938616e-07   \n",
      "2000-07-18  4997373.79    0.011981  0.000351     8.229788e-08   \n",
      "2000-07-19  5002406.38    0.005832  0.000320    -1.739181e-08   \n",
      "2000-07-20  5013745.52    0.016152  0.000299     1.807568e-09   \n",
      "2000-07-21  5015003.90   -0.002123  0.000316    -4.949254e-08   \n",
      "2000-07-24  5012388.75   -0.011690  0.000333    -1.465762e-08   \n",
      "2000-07-25  4998965.64   -0.020362  0.000333    -4.282158e-08   \n",
      "2000-07-26  4981479.44   -0.025400  0.000357     3.035661e-08   \n",
      "2000-07-27  4960530.57   -0.041791  0.001221    -9.917005e-06   \n",
      "2000-07-28  4932569.50   -0.044990  0.001295    -1.000013e-05   \n",
      "2000-07-31  4903476.38   -0.037116  0.001328    -9.921048e-06   \n",
      "2000-08-01  4883307.92   -0.025874  0.001314    -9.929241e-06   \n",
      "2000-08-02  4862036.40   -0.028287  0.001313    -9.948982e-06   \n",
      "2000-08-03  4833777.42   -0.042521  0.001372    -1.005644e-05   \n",
      "2000-08-04  4810670.43   -0.033760  0.001419    -9.873749e-06   \n",
      "2000-08-07  4798477.30   -0.001767  0.000561     1.523645e-07   \n",
      "2000-08-08  4799531.88    0.008594  0.000509     2.615185e-07   \n",
      "2000-08-09  4809345.95    0.006871  0.000490     2.969299e-07   \n",
      "...                ...         ...       ...              ...   \n",
      "2005-06-21  2435496.50    0.011314  0.000190     1.265995e-07   \n",
      "2005-06-22  2439596.48    0.007017  0.000193     1.178171e-07   \n",
      "2005-06-23  2474751.03    0.008795  0.000193     1.344114e-07   \n",
      "2005-06-24  2475049.53    0.004264  0.000245    -3.137498e-07   \n",
      "2005-06-27  2493902.86   -0.008769  0.000283    -7.670573e-07   \n",
      "2005-06-28  2506852.34   -0.005198  0.000262    -7.885559e-07   \n",
      "2005-06-29  2499288.66    0.005179  0.000258    -7.545165e-07   \n",
      "2005-06-30  2503585.14    0.000604  0.000252    -7.789191e-07   \n",
      "2005-07-01  2507739.04    0.008303  0.000262    -7.543156e-07   \n",
      "2005-07-04  2478828.95    0.007742  0.000252    -7.557540e-07   \n",
      "2005-07-05  2486200.71    0.014731  0.000198    -3.115264e-07   \n",
      "2005-07-06  2490402.35    0.028826  0.000158     1.196242e-07   \n",
      "2005-07-07  2491202.42    0.002546  0.000683    -2.641137e-06   \n",
      "2005-07-08  2498143.20    0.014378  0.000777    -1.874531e-06   \n",
      "2005-07-11  2504700.61    0.020181  0.000792    -1.794415e-06   \n",
      "2005-07-12  2490179.15    0.008602  0.000795    -1.832671e-06   \n",
      "2005-07-13  2500739.53    0.013919  0.000807    -1.826125e-06   \n",
      "2005-07-14  2509385.32    0.021370  0.000816    -1.791805e-06   \n",
      "2005-07-15  2518207.66    0.016793  0.000811    -1.825858e-06   \n",
      "2005-07-18  2531776.46    0.033022  0.000286     9.197934e-07   \n",
      "2005-07-19  2538376.47    0.027368  0.000196     1.682405e-07   \n",
      "2005-07-20  2541929.50    0.017551  0.000195     7.125489e-08   \n",
      "2005-07-21  2566021.18    0.019458  0.000394     3.927554e-07   \n",
      "2005-07-22  2547638.47    0.009842  0.000404     3.521856e-07   \n",
      "2005-07-25  2545933.53    0.006409  0.000399     3.369054e-07   \n",
      "2005-07-26  2545683.95    0.007375  0.000394     3.262309e-07   \n",
      "2005-07-27  2549265.86    0.010429  0.000400     3.265164e-07   \n",
      "2005-07-28  2552998.94    0.005714  0.000408     3.912077e-07   \n",
      "2005-07-29  2556552.04    0.006826  0.000406     4.170144e-07   \n",
      "2005-08-01  2379119.20    0.008518  0.000184     1.138844e-07   \n",
      "\n",
      "            logreturns_pow4  skewness      kurtosis  \n",
      "2000-06-29              NaN       NaN           NaN  \n",
      "2000-06-30              NaN       NaN           NaN  \n",
      "2000-07-03              NaN       NaN           NaN  \n",
      "2000-07-04              NaN       NaN           NaN  \n",
      "2000-07-05              NaN       NaN           NaN  \n",
      "2000-07-06              NaN       NaN           NaN  \n",
      "2000-07-07     4.979406e-09  0.243180    388.562417  \n",
      "2000-07-10     4.077681e-09  1.159749    779.776204  \n",
      "2000-07-11     3.157822e-09  0.706778    445.977029  \n",
      "2000-07-12     3.076569e-09  0.647512   1205.295623  \n",
      "2000-07-13     2.968995e-09  0.753600   1225.700533  \n",
      "2000-07-14     2.779835e-09  1.057979   1448.141182  \n",
      "2000-07-17     2.666611e-09  1.372648   1625.582646  \n",
      "2000-07-18     1.300576e-09  0.348156    383.841691  \n",
      "2000-07-19     8.502792e-10 -0.084740    639.139202  \n",
      "2000-07-20     6.345401e-10  0.009767    176.491707  \n",
      "2000-07-21     7.837135e-10 -0.245887    159.803015  \n",
      "2000-07-24     8.668458e-10 -0.067221    182.892118  \n",
      "2000-07-25     8.148989e-10 -0.196848    436.267668  \n",
      "2000-07-26     1.232247e-09  0.125556    266.244006  \n",
      "2000-07-27     2.590478e-07 -6.480680    240.244282  \n",
      "2000-07-28     2.595908e-07 -5.982081  17862.559553  \n",
      "2000-07-31     2.598685e-07 -5.716226  27522.940877  \n",
      "2000-08-01     2.598181e-07 -5.812842  88727.702077  \n",
      "2000-08-02     2.598274e-07 -5.829451  56217.503096  \n",
      "2000-08-03     2.603662e-07 -5.517456  21534.163890  \n",
      "2000-08-04     2.616699e-07 -5.147365  17592.912335  \n",
      "2000-08-07     3.989301e-09  0.319770    958.459952  \n",
      "2000-08-08     3.553869e-09  0.635112    938.000773  \n",
      "2000-08-09     3.651390e-09  0.762309    629.189222  \n",
      "...                     ...       ...           ...  \n",
      "2005-06-21     6.380842e-10  1.344140    700.502208  \n",
      "2005-06-22     6.390229e-10  1.225202   1126.676566  \n",
      "2005-06-23     6.238894e-10  1.395057   1091.007883  \n",
      "2005-06-24     3.947563e-09 -2.283116    527.140362  \n",
      "2005-06-27     6.473195e-09 -4.495636   1010.736175  \n",
      "2005-06-28     6.412155e-09 -5.178572  19440.740386  \n",
      "2005-06-29     6.442776e-09 -5.063874   6930.442976  \n",
      "2005-06-30     6.359291e-09 -5.418926  11772.280300  \n",
      "2005-07-01     6.419208e-09 -4.962035   5331.543967  \n",
      "2005-07-04     6.404838e-09 -5.269747  40367.946404  \n",
      "2005-07-05     3.045600e-09 -3.119665   4769.576983  \n",
      "2005-07-06     3.756573e-10  1.674354    304.620684  \n",
      "2005-07-07     3.771723e-08 -4.126803    100.329531  \n",
      "2005-07-08     4.482398e-08 -2.413270   2379.961949  \n",
      "2005-07-11     4.517425e-08 -2.243681  27463.223693  \n",
      "2005-07-12     4.515585e-08 -2.280879  32127.182654  \n",
      "2005-07-13     4.517597e-08 -2.220944  64067.096499  \n",
      "2005-07-14     4.526782e-08 -2.142822  35715.212200  \n",
      "2005-07-15     4.518833e-08 -2.204642  52990.913288  \n",
      "2005-07-18     7.829175e-09  5.312720  26059.420911  \n",
      "2005-07-19     7.358455e-10  1.715518    598.736226  \n",
      "2005-07-20     4.256178e-10  0.726668    258.996892  \n",
      "2005-07-21     5.308845e-09  1.400790     77.046652  \n",
      "2005-07-22     5.388183e-09  1.210479   3789.157858  \n",
      "2005-07-25     5.342499e-09  1.178109   5794.188822  \n",
      "2005-07-26     5.306909e-09  1.164344   9967.901395  \n",
      "2005-07-27     5.339606e-09  1.136271   8595.918296  \n",
      "2005-07-28     5.723405e-09  1.322219   2958.408564  \n",
      "2005-07-29     5.740374e-09  1.420938   3967.656648  \n",
      "2005-08-01     8.116946e-10  1.273434   7392.280054  \n",
      "\n",
      "[1294 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import 5 min price data and calc log returns\n",
    "# --------------------------------------------------\n",
    "es_50_prices_5 = pd.read_csv('data/eurostoxx50_prices_5m.csv', parse_dates=True, sep=';')\n",
    "# set index, rename and check\n",
    "es_50_prices_5 = es_50_prices_5.rename(columns={'loctimestamp': 'date'})\n",
    "es_50_prices_5['date'] = pd.to_datetime(es_50_prices_5['date'], errors='coerce')\n",
    "es_50_prices_5 = es_50_prices_5.set_index('date')\n",
    "\n",
    "#Log Returns\n",
    "es_50_logret_5 = es_50_prices_5\n",
    "es_50_logret_5['logreturns'] = np.log(es_50_prices_5['price'] / es_50_prices_5['price'].shift(1))\n",
    "es_50_logret_5 = es_50_logret_5.dropna()\n",
    "\n",
    "# Count of values per day\n",
    "N = (es_50_logret_5.loc[(es_50_logret_5.index >= '2004-07-04 00:00:00') & (es_50_logret_5.index <= '2004-07-06 00:00:00')]).shape[0]\n",
    "\n",
    "# Calculate moments after Amaya, Christoffersen, Jacobs, Vasquez (2015) - Does realized skewness predict equity returns\n",
    "es_50_logret_5['logreturns_pow2'] = es_50_logret_5['logreturns'] ** 2\n",
    "es_50_logret_5['logreturns_pow3'] = es_50_logret_5['logreturns'] ** 3\n",
    "es_50_logret_5['logreturns_pow4'] = es_50_logret_5['logreturns'] ** 4\n",
    "\n",
    "# group by date and sum up\n",
    "es_50_P_1 = es_50_logret_5.groupby(es_50_logret_5.index.date).sum()\n",
    "\n",
    "# Var 1 day = sum of intraday squared returns\n",
    "es_50_P_1 = es_50_P_1.rename(columns={'logreturns_pow2': 'var'})\n",
    "# Skewness 1 day\n",
    "es_50_P_1['skewness'] = ( np.sqrt(N) * es_50_P_1['logreturns_pow3']) / (es_50_P_1['var'] ** (3 / 2) )\n",
    "# Kurtosis 1 day\n",
    "es_50_P_1['kurtosis'] = N * es_50_P_1['logreturns_pow4'] / (es_50_P_1['var'] ** 2)\n",
    "\n",
    "# Var 7 days = sum of intraday squared returns\n",
    "es_50_P_7 = es_50_P_1.rolling(7).sum()\n",
    "# Skewness 7 days\n",
    "es_50_P_7['skewness'] = (np.sqrt(N*7) * es_50_P_1['logreturns_pow3'].rolling(7).sum()) / (es_50_P_7['var'] ** (3 / 2) )\n",
    "# Kurtosis 7 days\n",
    "es_50_P_7['kurtosis'] = (N* 7 * es_50_P_1['logreturns_pow4'].rolling(7).sum()) / (es_50_P_1['var'] ** 2)\n",
    "\n",
    "# Var 30 days = sum of intraday squared returns\n",
    "es_50_P_30 = es_50_P_1.rolling(30).sum()\n",
    "# Skewness 7 days\n",
    "es_50_P_30['skewness'] = (np.sqrt(N * 30) * es_50_P_1['logreturns_pow3'].rolling(30).sum()) / (es_50_P_30['var'] ** (3 / 2) )\n",
    "# Kurtosis 7 days\n",
    "es_50_P_30['kurtosis'] = (N* 30 * es_50_P_1['logreturns_pow4'].rolling(30).sum()) / (es_50_P_30['var'] ** 2)\n",
    "\n",
    "# Var 60 days = sum of intraday squared returns\n",
    "es_50_P_60 = es_50_P_1.rolling(60).sum()\n",
    "# Skewness 7 days\n",
    "es_50_P_60['skewness'] = (np.sqrt(N * 60) * es_50_P_1['logreturns_pow3'].rolling(60).sum()) / (es_50_P_60['var'] ** (3 / 2) )\n",
    "# Kurtosis 7 days\n",
    "es_50_P_60['kurtosis'] = (N* 60 * es_50_P_1['logreturns_pow4'].rolling(60).sum()) / (es_50_P_60['var'] ** 2)\n",
    "\n",
    "\n",
    "\n",
    "del es_50_P_1['price']\n",
    "del es_50_P_1['logreturns']\n",
    "del es_50_P_1['logreturns_pow3']\n",
    "del es_50_P_1['logreturns_pow4']\n",
    "\n",
    "print(es_50_P_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fama-French data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Fama French Factors\n",
    "# --------------------------------------------------\n",
    "# HML and SMB\n",
    "es_50_ff = pd.read_csv('data/FamaFrench_Europe_3_Factors_Daily.csv', parse_dates=True, skiprows=6)\n",
    "es_50_ff = es_50_ff.rename(columns={'Unnamed: 0': 'date'})\n",
    "es_50_ff['date'] = pd.to_datetime(es_50_ff['date'], format = '%Y%m%d')\n",
    "es_50_ff = es_50_ff.set_index('date')\n",
    "\n",
    "# Momentum Factor\n",
    "es_50_ff2 = pd.read_csv('data/FamaFrench_Europe_MOM_Factor_Daily.csv', parse_dates=True, skiprows=6)\n",
    "es_50_ff2 = es_50_ff2.rename(columns={'Unnamed: 0': 'date'})\n",
    "es_50_ff2['date'] = pd.to_datetime(es_50_ff2['date'], format = '%Y%m%d')\n",
    "es_50_ff2 = es_50_ff2.set_index('date')\n",
    "\n",
    "# Join and drop na's\n",
    "es_50_ff = es_50_ff.join(es_50_ff2).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join data for correct dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join vol and implied vol\n",
    "print(es_50_logret['logreturns'].shape)\n",
    "print(es_50_vol.shape)\n",
    "print(es_50_imp_vol.shape)\n",
    "print(es_50_vrp.shape)\n",
    "print(es_50_erp.shape)\n",
    "print(es_50_q.shape)\n",
    "print(es_50_P.shape)\n",
    "print(es_50_ff.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Ex ante Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model and Analysis\n",
    "# ==================================================\n",
    "#\n",
    "# 1. Estimate (sigma_t)2, the (ex ante) conditional variance of next-period unexpected returns epsilon_(t+1)\n",
    "# using a HAR-RV (Hierachical Autoregressive-Realized Variance) Model from Corsi (2009)\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# First, instantiate object\n",
    "# no implied vol\n",
    "ea_var_obj = ExAnteVariance(es_50_vol)\n",
    "# implied vol exists\n",
    "# ea_var_obj = ExAnteVariance(es_50_imp_vol, es_50_imp_vol['implied_vol'])\n",
    "\n",
    "# Estimate Variance\n",
    "result = ea_var_obj.estimate_variance()\n",
    "result = result.dropna()\n",
    "\n",
    "# Join returns and estimated variance\n",
    "wlsev_var_rets = es_50_logret.join(result).dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WLS-EV and benchmark estimations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress returns on returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forecast horizon 1, 5 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. least squares estimates weighted by ex-ante return variance (WLS-EV) using Johnson (2016)\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for i in (1,5,10):\n",
    "    # set forecast_horizon\n",
    "    forecast_horizon = i\n",
    "\n",
    "    # WLS-EV\n",
    "    wlsev_obj = Wlsev_model(wlsev_var_rets['logreturns'][:-1].as_matrix(), wlsev_var_rets['logreturns'][1:].as_matrix(), wlsev_var_rets['vol_daily_est'][:-1].as_matrix(), forecast_horizon)\n",
    "    wlsev_obj.fit()\n",
    "    # OOS evaluation to get Rsquared\n",
    "    wlsev_obj.evaluate()\n",
    "    wlsev_obj.print_results()\n",
    "    wlsev_obj.plot_results()\n",
    "    # get data\n",
    "    X, Y, y_wlsev = wlsev_obj.get_plot_data_wlsev()\n",
    "\n",
    "    # OLS\n",
    "    ols_obj = OLS_model(wlsev_var_rets['logreturns'][:-1].as_matrix(), wlsev_var_rets['logreturns'][1:].as_matrix(), forecast_horizon)\n",
    "    ols_obj.fit()\n",
    "    # OOS evaluation to get Rsquared\n",
    "    ols_obj.evaluate()\n",
    "    ols_obj.print_results()\n",
    "    ols_obj.plot_results()\n",
    "    # get data\n",
    "    X, Y, y_ols = ols_obj.get_plot_data_ols()\n",
    "\n",
    "\n",
    "    # Visualisation\n",
    "    # ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # time series plot\n",
    "    visualisation.plot_results(X,Y,y_wlsev, y_ols)\n",
    "    # scatter plot\n",
    "    visualisation.plot_scatter(X,Y,y_wlsev, y_ols)\n",
    "\n",
    "\n",
    "    # Get Simon's OLS estimation results\n",
    "    if forecast_horizon == 1:\n",
    "        ols_model = OLS(wlsev_var_rets['logreturns'][:-1].as_matrix(), wlsev_var_rets['logreturns'][1:].as_matrix())\n",
    "        ols_model.fit()\n",
    "        ols_model.printResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress returns on VRP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join vrp data with wls-ev log rets and ex ante variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_50_vrp_rets_var = wlsev_var_rets.join(es_50_vrp).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### forecast horizon months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set forecast_horizon\n",
    "for i in (1,22,44, 66, 88):\n",
    "    forecast_horizon = i\n",
    "\n",
    "    # WLS-EV\n",
    "    wlsev_obj = Wlsev_model(es_50_vrp_rets_var['vrp'][:-1].as_matrix(), es_50_vrp_rets_var['logreturns'][1:].as_matrix(), es_50_vrp_rets_var['vol_daily_est'][:-1].as_matrix(), forecast_horizon)\n",
    "    wlsev_obj.fit()\n",
    "    # OOS evaluation to get Rsquared\n",
    "    wlsev_obj.evaluate()\n",
    "    wlsev_obj.print_results()\n",
    "    wlsev_obj.plot_results()\n",
    "    # get data\n",
    "    X, Y, y_wlsev = wlsev_obj.get_plot_data_wlsev()\n",
    "\n",
    "    # OLS\n",
    "    ols_obj = OLS_model(es_50_vrp_rets_var['vrp'][:-1].as_matrix(), es_50_vrp_rets_var['logreturns'][1:].as_matrix(), forecast_horizon)\n",
    "    ols_obj.fit()\n",
    "    # OOS evaluation to get Rsquared\n",
    "    ols_obj.evaluate()\n",
    "    ols_obj.print_results()\n",
    "    # get data\n",
    "    X, Y, y_ols = ols_obj.get_plot_data_ols()\n",
    "\n",
    "\n",
    "    # Visualisation\n",
    "    # ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # time series plot\n",
    "    visualisation.plot_results(X,Y,y_wlsev, y_ols)\n",
    "    # scatter plot\n",
    "    visualisation.plot_scatter(X,Y,y_wlsev, y_ols)\n",
    "\n",
    "    # Get Simon's OLS estimation results\n",
    "    if forecast_horizon == 1:\n",
    "        ols_model = OLS(es_50_vrp_rets_var['vrp'][:-1].as_matrix(), es_50_vrp_rets_var['logreturns'][1:].as_matrix())\n",
    "        ols_model.fit()\n",
    "        ols_model.printResults()\n",
    "        ols_obj.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress ERP on VRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress P-Moments on Q-Moments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regress Fama French Factors on Q-Moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
